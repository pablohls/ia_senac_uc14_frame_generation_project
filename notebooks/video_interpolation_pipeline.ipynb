{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d515bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import wandb  # Para tracking de experimentos\n",
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "import json\n",
    "\n",
    "# Import device utilities\n",
    "from src.device_utils import validate_device, get_optimal_device, get_optimal_num_workers, print_device_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9d610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect best device for current platform\n",
    "print_device_info()\n",
    "\n",
    "device = validate_device(\"auto\")\n",
    "print(f\"\\n‚úì Using device: {device}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec3d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vimeo90kDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset para Vimeo-90k Triplet\n",
    "    Carrega triplas de frames para treinamento de interpola√ß√£o\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        is_train: bool = True,\n",
    "        transform=None,\n",
    "        crop_size: Tuple[int, int] = (256, 256),\n",
    "        cache=True  # NOVO: ativar cache\n",
    "    ):\n",
    "        print(\"Initializing Vimeo90kDataset...\")\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.is_train = is_train\n",
    "        self.crop_size = crop_size\n",
    "        self.cache = cache\n",
    "        self.image_cache = {}  # NOVO: dicion√°rio de cache\n",
    "\n",
    "        print(f\"Data directory: {self.data_dir}\")\n",
    "        # Carregar lista de sequ√™ncias\n",
    "        list_file = 'tri_trainlist.txt' if is_train else 'tri_testlist.txt'\n",
    "        list_path = self.data_dir / list_file\n",
    "        \n",
    "        print(f\"List file path: {list_path}\")\n",
    "\n",
    "        with open(list_path, 'r') as f:\n",
    "            self.triplets = [line.strip() for line in f.readlines()]\n",
    "            print(f\"First 5 triplets: {self.triplets[:5]}\")\n",
    "        \n",
    "        print(f\"Loaded {len(self.triplets)} triplets for {'training' if is_train else 'testing'}\")\n",
    "        \n",
    "        # Transforma√ß√µes\n",
    "        if transform is None:\n",
    "            if is_train:\n",
    "                self.transform = transforms.Compose([\n",
    "                    transforms.RandomCrop(crop_size),\n",
    "                    transforms.RandomHorizontalFlip(p=0.5),\n",
    "                    transforms.RandomVerticalFlip(p=0.5),\n",
    "                ])\n",
    "            else:\n",
    "                self.transform = transforms.Compose([\n",
    "                    transforms.CenterCrop(crop_size),\n",
    "                ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Triplet path: 00001/0001\n",
    "        triplet_path = self.triplets[idx]\n",
    "        base_path = self.data_dir / 'sequences' / triplet_path\n",
    "        \n",
    "        # Carregar os 3 frames (com cache)\n",
    "        frame1 = self._load_image(base_path / 'im1.png')\n",
    "        frame2 = self._load_image(base_path / 'im2.png')  # Ground truth (meio)\n",
    "        frame3 = self._load_image(base_path / 'im3.png')\n",
    "        \n",
    "        # Stack para aplicar mesmas transforma√ß√µes\n",
    "        frames = torch.cat([frame1, frame2, frame3], dim=0)\n",
    "        \n",
    "        # Aplicar transforma√ß√µes\n",
    "        if self.transform:\n",
    "            frames = self.transform(frames)\n",
    "        \n",
    "        # Separar frames novamente\n",
    "        frame1 = frames[:3, :, :]\n",
    "        frame2 = frames[3:6, :, :]\n",
    "        frame3 = frames[6:9, :, :]\n",
    "        \n",
    "        return {\n",
    "            'frame1': frame1,\n",
    "            'frame2': frame2,  # Ground truth\n",
    "            'frame3': frame3,\n",
    "            'triplet_path': triplet_path\n",
    "        }\n",
    "    \n",
    "    def _load_image(self, path: Path) -> torch.Tensor:\n",
    "        \"\"\"Carregar imagem e converter para tensor (com cache)\"\"\"\n",
    "        path_str = str(path)\n",
    "        \n",
    "        # Se est√° em cache e cache est√° ativado, retornar do cache\n",
    "        if self.cache and path_str in self.image_cache:\n",
    "            return self.image_cache[path_str].clone()\n",
    "        \n",
    "        # Sen√£o, carregar do disco\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        img_tensor = transforms.ToTensor()(img)\n",
    "        \n",
    "        # Guardar no cache se ativado\n",
    "        if self.cache:\n",
    "            self.image_cache[path_str] = img_tensor\n",
    "        \n",
    "        return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f236b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels // 8, 1),  # Comprimir\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels // 8, channels, 1),  # Expandir\n",
    "            nn.Sigmoid()  # Valores entre 0 e 1 (peso de aten√ß√£o)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attention_weights = self.attention(x)  # Mapa de aten√ß√£o\n",
    "        return x * attention_weights  # Multiplica features pelo peso\n",
    "    \n",
    "class UNetInterpolator(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net para Frame Interpolation\n",
    "    Input: frame1 + frame3 (6 canais)\n",
    "    Output: frame2 interpolado (3 canais)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=6, out_channels=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(in_channels, 64)\n",
    "        self.enc2 = ConvBlock(64, 128)\n",
    "        self.enc3 = ConvBlock(128, 256)\n",
    "        self.enc4 = ConvBlock(256, 512)\n",
    "        # self.enc5 = ConvBlock(512, 1024)\n",
    "\n",
    "        self.att3 = AttentionBlock(256)\n",
    "        self.att4 = AttentionBlock(512)\n",
    "        \n",
    "        # Bottleneck\n",
    "        # self.bottleneck = ConvBlock(256, 512)\n",
    "        self.bottleneck = ConvBlock(512, 1024)\n",
    "        # self.bottleneck = ConvBlock(1024, 2048)\n",
    "        \n",
    "        # Decoder\n",
    "        # self.upconv5 = nn.ConvTranspose2d(2048, 1024, 2, stride=2)\n",
    "        # self.dec5 = ConvBlock(2048, 1024)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.dec4 = ConvBlock(1024, 512)\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec3 = ConvBlock(512, 256)\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec2 = ConvBlock(256, 128)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = ConvBlock(128, 64)\n",
    "        \n",
    "        # Output\n",
    "        self.out = nn.Conv2d(64, out_channels, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, frame1, frame3):\n",
    "        # Concatenar frames de entrada\n",
    "        x = torch.cat([frame1, frame3], dim=1)\n",
    "        \n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        x = self.pool(enc1)\n",
    "        \n",
    "        enc2 = self.enc2(x)\n",
    "        x = self.pool(enc2)\n",
    "        \n",
    "        enc3 = self.enc3(x)\n",
    "        enc3 = self.att3(enc3)  # Aten√ß√£o\n",
    "        x = self.pool(enc3)\n",
    "        \n",
    "        enc4 = self.enc4(x)\n",
    "        enc4 = self.att4(enc4)  # Aten√ß√£o\n",
    "        x = self.pool(enc4)\n",
    "        \n",
    "        # enc5 = self.enc5(x)\n",
    "        # x = self.pool(enc5)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        # x = self.upconv5(x)\n",
    "        # x = torch.cat([x, enc5], dim=1)\n",
    "        # x = self.dec5(x)\n",
    "        \n",
    "        x = self.upconv4(x)\n",
    "        x = torch.cat([x, enc4], dim=1)\n",
    "        x = self.dec4(x)\n",
    "        \n",
    "        x = self.upconv3(x)\n",
    "        x = torch.cat([x, enc3], dim=1)\n",
    "        x = self.dec3(x)\n",
    "        \n",
    "        x = self.upconv2(x)\n",
    "        x = torch.cat([x, enc2], dim=1)\n",
    "        x = self.dec2(x)\n",
    "        \n",
    "        x = self.upconv1(x)\n",
    "        x = torch.cat([x, enc1], dim=1)\n",
    "        x = self.dec1(x)\n",
    "        \n",
    "        # Output\n",
    "        out = self.out(x)\n",
    "        out = torch.sigmoid(out)  # Valores entre 0 e 1\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combina√ß√£o de m√∫ltiplas losses para melhor qualidade:\n",
    "- L1 Loss: Reconstru√ß√£o pixel-wise\n",
    "- Perceptual Loss: Similaridade em features de alto n√≠vel\n",
    "- SSIM Loss: Similaridade estrutural\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    import lpips\n",
    "    LPIPS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LPIPS_AVAILABLE = False\n",
    "    print(\"Warning: lpips not available. Install with: pip install lpips\")\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, device='auto'):\n",
    "        super().__init__()\n",
    "        # Validate device\n",
    "        device = validate_device(device)\n",
    "        \n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "        # Perceptual loss usando LPIPS\n",
    "        if LPIPS_AVAILABLE:\n",
    "            self.lpips_loss = lpips.LPIPS(net='alex').to(device)\n",
    "        else:\n",
    "            self.lpips_loss = None\n",
    "        \n",
    "        # Pesos das losses\n",
    "        self.w_l1 = 1.0\n",
    "        self.w_perceptual = 0.1 if LPIPS_AVAILABLE else 0.0\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # L1 Loss\n",
    "        loss_l1 = self.l1_loss(pred, target)\n",
    "        \n",
    "        total_loss = self.w_l1 * loss_l1\n",
    "        \n",
    "        # Perceptual Loss\n",
    "        if self.lpips_loss is not None:\n",
    "            # LPIPS espera valores em [-1, 1]\n",
    "            pred_norm = pred * 2 - 1\n",
    "            target_norm = target * 2 - 1\n",
    "            loss_perceptual = self.lpips_loss(pred_norm, target_norm).mean()\n",
    "            total_loss += self.w_perceptual * loss_perceptual\n",
    "        \n",
    "        return total_loss, {\n",
    "            'l1': loss_l1.item(),\n",
    "            'perceptual': loss_perceptual.item() if self.lpips_loss else 0.0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d13346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(pred, target):\n",
    "    \"\"\"Calculate Peak Signal-to-Noise Ratio\"\"\"\n",
    "    mse = torch.mean((pred - target) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    max_pixel = 1.0\n",
    "    psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse))\n",
    "    return psnr.item()\n",
    "\n",
    "def calculate_ssim(pred, target):\n",
    "    \"\"\"Calculate Structural Similarity Index (simplificado)\"\"\"\n",
    "    # Para SSIM completo, use pytorch-msssim\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "    \n",
    "    mu_pred = torch.mean(pred)\n",
    "    mu_target = torch.mean(target)\n",
    "    \n",
    "    sigma_pred = torch.var(pred)\n",
    "    sigma_target = torch.var(target)\n",
    "    sigma_pred_target = torch.mean((pred - mu_pred) * (target - mu_target))\n",
    "    \n",
    "    ssim = ((2 * mu_pred * mu_target + C1) * (2 * sigma_pred_target + C2)) / \\\n",
    "           ((mu_pred ** 2 + mu_target ** 2 + C1) * (sigma_pred + sigma_target + C2))\n",
    "    \n",
    "    return ssim.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f40d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        device,\n",
    "        config\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        \n",
    "        self.best_val_loss = float('inf')\n",
    "        self.start_epoch = 0\n",
    "\n",
    "        self.training_history = {\n",
    "            'epoch': [],\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_psnr': [],\n",
    "            'val_ssim': [],\n",
    "            'learning_rate': [],\n",
    "            'timestamp': []\n",
    "        }\n",
    "\n",
    "        # Criar diret√≥rio de logs\n",
    "        self.log_dir = Path(config.get('logging', {}).get('log_dir', 'logs'))\n",
    "        self.log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Timestamp para esta sess√£o de treinamento\n",
    "        from datetime import datetime\n",
    "        self.session_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.log_file = self.log_dir / f'training_log_{self.session_id}.csv'\n",
    "        \n",
    "        print(f\"üìä Logs ser√£o salvos em: {self.log_file}\")\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(self.train_loader, desc=f'Epoch {epoch}')\n",
    "        \n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            frame1 = batch['frame1'].to(self.device)\n",
    "            frame2 = batch['frame2'].to(self.device)  # Ground truth\n",
    "            frame3 = batch['frame3'].to(self.device)\n",
    "            \n",
    "            # Forward\n",
    "            pred_frame2 = self.model(frame1, frame3)\n",
    "            \n",
    "            # Loss\n",
    "            loss, loss_dict = self.criterion(pred_frame2, frame2)\n",
    "            \n",
    "            # Backward\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'l1': f'{loss_dict[\"l1\"]:.4f}'\n",
    "            })\n",
    "            \n",
    "            # Log to wandb\n",
    "            if self.config.get('use_wandb', False):\n",
    "                wandb.log({\n",
    "                    'train/loss': loss.item(),\n",
    "                    'train/l1_loss': loss_dict['l1'],\n",
    "                    'train/perceptual_loss': loss_dict['perceptual'],\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "        \n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        return avg_loss\n",
    "    \n",
    "    def validate(self, epoch):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_psnr = 0\n",
    "        total_ssim = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.val_loader, desc='Validation'):\n",
    "                frame1 = batch['frame1'].to(self.device)\n",
    "                frame2 = batch['frame2'].to(self.device)\n",
    "                frame3 = batch['frame3'].to(self.device)\n",
    "                \n",
    "                pred_frame2 = self.model(frame1, frame3)\n",
    "                \n",
    "                loss, _ = self.criterion(pred_frame2, frame2)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Calcular m√©tricas\n",
    "                psnr = calculate_psnr(pred_frame2, frame2)\n",
    "                ssim = calculate_ssim(pred_frame2, frame2)\n",
    "                \n",
    "                total_psnr += psnr\n",
    "                total_ssim += ssim\n",
    "        \n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        avg_psnr = total_psnr / len(self.val_loader)\n",
    "        avg_ssim = total_ssim / len(self.val_loader)\n",
    "        \n",
    "        print(f'\\nValidation - Loss: {avg_loss:.4f}, PSNR: {avg_psnr:.2f}, SSIM: {avg_ssim:.4f}')\n",
    "        \n",
    "        if self.config.get('use_wandb', False):\n",
    "            wandb.log({\n",
    "                'val/loss': avg_loss,\n",
    "                'val/psnr': avg_psnr,\n",
    "                'val/ssim': avg_ssim,\n",
    "                'epoch': epoch\n",
    "            })\n",
    "        \n",
    "        return avg_loss, avg_psnr, avg_ssim\n",
    "    \n",
    "    def log_epoch(self, epoch, train_loss, val_loss, val_psnr, val_ssim):\n",
    "        \"\"\"NOVO: Registrar m√©tricas de cada epoch\"\"\"\n",
    "        from datetime import datetime\n",
    "        \n",
    "        # Pegar learning rate atual\n",
    "        current_lr = self.optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Adicionar ao hist√≥rico\n",
    "        self.training_history['epoch'].append(epoch)\n",
    "        self.training_history['train_loss'].append(train_loss)\n",
    "        self.training_history['val_loss'].append(val_loss)\n",
    "        self.training_history['val_psnr'].append(val_psnr)\n",
    "        self.training_history['val_ssim'].append(val_ssim)\n",
    "        self.training_history['learning_rate'].append(current_lr)\n",
    "        self.training_history['timestamp'].append(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        \n",
    "        # Salvar em CSV\n",
    "        import csv\n",
    "        file_exists = self.log_file.exists()\n",
    "        \n",
    "        with open(self.log_file, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            \n",
    "            # Escrever header se arquivo novo\n",
    "            if not file_exists:\n",
    "                writer.writerow(['epoch', 'train_loss', 'val_loss', 'val_psnr', \n",
    "                               'val_ssim', 'learning_rate', 'timestamp'])\n",
    "            \n",
    "            # Escrever dados\n",
    "            writer.writerow([epoch, f'{train_loss:.6f}', f'{val_loss:.6f}', \n",
    "                           f'{val_psnr:.2f}', f'{val_ssim:.4f}', \n",
    "                           f'{current_lr:.8f}', \n",
    "                           self.training_history['timestamp'][-1]])\n",
    "\n",
    "    def save_checkpoint(self, epoch, val_loss, is_best=False):\n",
    "        checkpoint_dir = Path(self.config['paths']['finetuned_dir'])\n",
    "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'config': self.config,\n",
    "            'training_history': self.training_history\n",
    "        }\n",
    "        \n",
    "        # Save regular checkpoint\n",
    "        if epoch % self.config['training']['checkpoint_freq'] == 0:\n",
    "            path = checkpoint_dir / f'checkpoint_epoch_{epoch}.pt'\n",
    "            torch.save(checkpoint, path)\n",
    "            print(f'Checkpoint saved: {path}')\n",
    "        \n",
    "        # Save best model\n",
    "        if is_best:\n",
    "            path = checkpoint_dir / 'best_model.pt'\n",
    "            torch.save(checkpoint, path)\n",
    "            print(f'Best model saved: {path}')\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"NOVO: Criar gr√°ficos do hist√≥rico de treinamento\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle(f'Training Summary - Session {self.session_id}', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        epochs = self.training_history['epoch']\n",
    "        \n",
    "        # 1. Loss (Train vs Val)\n",
    "        axes[0, 0].plot(epochs, self.training_history['train_loss'], 'b-o', label='Train Loss', linewidth=2)\n",
    "        axes[0, 0].plot(epochs, self.training_history['val_loss'], 'r-o', label='Val Loss', linewidth=2)\n",
    "        axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
    "        axes[0, 0].set_title('Training & Validation Loss', fontsize=14)\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. PSNR\n",
    "        axes[0, 1].plot(epochs, self.training_history['val_psnr'], 'g-o', linewidth=2)\n",
    "        axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[0, 1].set_ylabel('PSNR (dB)', fontsize=12)\n",
    "        axes[0, 1].set_title('Validation PSNR', fontsize=14)\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. SSIM\n",
    "        axes[1, 0].plot(epochs, self.training_history['val_ssim'], 'm-o', linewidth=2)\n",
    "        axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[1, 0].set_ylabel('SSIM', fontsize=12)\n",
    "        axes[1, 0].set_title('Validation SSIM', fontsize=14)\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Learning Rate\n",
    "        axes[1, 1].plot(epochs, self.training_history['learning_rate'], 'orange', linewidth=2)\n",
    "        axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "        axes[1, 1].set_title('Learning Rate Schedule', fontsize=14)\n",
    "        axes[1, 1].set_yscale('log')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Salvar figura\n",
    "        plot_path = self.log_dir / f'training_summary_{self.session_id}.png'\n",
    "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "        print(f'\\nüìä Gr√°fico de treinamento salvo em: {plot_path}')\n",
    "        plt.show()\n",
    "    \n",
    "    def print_training_summary(self):\n",
    "        \"\"\"NOVO: Imprimir resumo textual do treinamento\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"{'TRAINING SUMMARY':^70}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(f\"\\nüìÖ Session ID: {self.session_id}\")\n",
    "        print(f\"üìÅ Log file: {self.log_file}\")\n",
    "        print(f\"üî¢ Total epochs: {len(self.training_history['epoch'])}\")\n",
    "        \n",
    "        if len(self.training_history['epoch']) > 0:\n",
    "            # Melhor epoch\n",
    "            best_epoch_idx = np.argmin(self.training_history['val_loss'])\n",
    "            best_epoch = self.training_history['epoch'][best_epoch_idx]\n",
    "            \n",
    "            print(f\"\\nüèÜ Best Performance (Epoch {best_epoch}):\")\n",
    "            print(f\"   ‚Ä¢ Val Loss:  {self.training_history['val_loss'][best_epoch_idx]:.4f}\")\n",
    "            print(f\"   ‚Ä¢ Val PSNR:  {self.training_history['val_psnr'][best_epoch_idx]:.2f} dB\")\n",
    "            print(f\"   ‚Ä¢ Val SSIM:  {self.training_history['val_ssim'][best_epoch_idx]:.4f}\")\n",
    "            \n",
    "            # √öltima epoch\n",
    "            last_idx = -1\n",
    "            print(f\"\\nüìà Final Performance (Epoch {self.training_history['epoch'][last_idx]}):\")\n",
    "            print(f\"   ‚Ä¢ Train Loss: {self.training_history['train_loss'][last_idx]:.4f}\")\n",
    "            print(f\"   ‚Ä¢ Val Loss:   {self.training_history['val_loss'][last_idx]:.4f}\")\n",
    "            print(f\"   ‚Ä¢ Val PSNR:   {self.training_history['val_psnr'][last_idx]:.2f} dB\")\n",
    "            print(f\"   ‚Ä¢ Val SSIM:   {self.training_history['val_ssim'][last_idx]:.4f}\")\n",
    "            \n",
    "            # Improvement\n",
    "            improvement_loss = self.training_history['val_loss'][0] - self.training_history['val_loss'][last_idx]\n",
    "            improvement_psnr = self.training_history['val_psnr'][last_idx] - self.training_history['val_psnr'][0]\n",
    "            \n",
    "            print(f\"\\nüìä Overall Improvement:\")\n",
    "            print(f\"   ‚Ä¢ Val Loss: {improvement_loss:+.4f} ({improvement_loss/self.training_history['val_loss'][0]*100:+.1f}%)\")\n",
    "            print(f\"   ‚Ä¢ Val PSNR: {improvement_psnr:+.2f} dB\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        print(f'Starting training for {num_epochs} epochs...')\n",
    "        \n",
    "        for epoch in range(self.start_epoch, num_epochs):\n",
    "            # Train\n",
    "            train_loss = self.train_epoch(epoch)\n",
    "            print(f'Epoch {epoch} - Train Loss: {train_loss:.4f}')\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_psnr, val_ssim = self.validate(epoch)\n",
    "            \n",
    "            # Save checkpoint\n",
    "            is_best = val_loss < self.best_val_loss\n",
    "            if is_best:\n",
    "                self.best_val_loss = val_loss\n",
    "            \n",
    "            self.save_checkpoint(epoch, val_loss, is_best)\n",
    "            \n",
    "        \n",
    "        print('Training completed!')\n",
    "        self.plot_training_summary()\n",
    "        self.print_training_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6364e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import Subset\n",
    "import random\n",
    "\n",
    "# Tenta achar config.yaml no cwd; se n√£o, no pai\n",
    "candidates = [Path.cwd(), Path.cwd().parent]\n",
    "PROJECT_ROOT = None\n",
    "for c in candidates:\n",
    "    if (c / 'config.yaml').exists():\n",
    "        PROJECT_ROOT = c\n",
    "        break\n",
    "if PROJECT_ROOT is None:\n",
    "    raise FileNotFoundError(\"config.yaml n√£o encontrado; ajuste PROJECT_ROOT manualmente\")\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "\n",
    "with open(PROJECT_ROOT / 'config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Caminho absoluto para o Vimeo-90k\n",
    "VIMEO_DATA_DIR = PROJECT_ROOT / config['paths']['data_dir'] / 'vimeo_triplet'\n",
    "print(\"Vimeo Dataset Directory:\", VIMEO_DATA_DIR)\n",
    "\n",
    "# Sanidade\n",
    "assert (VIMEO_DATA_DIR / 'tri_trainlist.txt').exists(), \"tri_trainlist.txt n√£o encontrado\"\n",
    "\n",
    "# Criar datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_dataset_full = Vimeo90kDataset(\n",
    "    data_dir=VIMEO_DATA_DIR,\n",
    "    is_train=True,\n",
    "    crop_size=(256, 256),\n",
    "    cache=False\n",
    ")\n",
    "val_dataset_full = Vimeo90kDataset(\n",
    "    data_dir=VIMEO_DATA_DIR,\n",
    "    is_train=False,\n",
    "    crop_size=(256, 256),\n",
    "    cache=False\n",
    ")\n",
    "\n",
    "# TESTE R√ÅPIDO: Usar apenas 20% dos dados\n",
    "SUBSET_RATIO = 0.20  # 20% dos dados\n",
    "train_size = int(len(train_dataset_full) * SUBSET_RATIO)\n",
    "val_size = int(len(val_dataset_full) * SUBSET_RATIO)\n",
    "\n",
    "train_indices = random.sample(range(len(train_dataset_full)), train_size)\n",
    "val_indices = random.sample(range(len(val_dataset_full)), val_size)\n",
    "train_dataset = Subset(train_dataset_full, train_indices)\n",
    "val_dataset = Subset(val_dataset_full, val_indices)\n",
    "\n",
    "print(f\"Using {SUBSET_RATIO*100}% subset: {len(train_dataset)} train, {len(val_dataset)} val samples\")\n",
    "\n",
    "# Get optimal num_workers for current platform\n",
    "optimal_workers = get_optimal_num_workers()\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=optimal_workers,  # Auto-detect: 0 for Mac, 4 for Windows/Linux\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=optimal_workers,  # Auto-detect: 0 for Mac, 4 for Windows/Linux\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Criar modelo\n",
    "model = UNetInterpolator(in_channels=6, out_channels=3).to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Optimizer e Loss\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config['training']['learning_rate'],\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "criterion = CombinedLoss(device=str(device))\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "# Inicializar Weights & Biases (opcional)\n",
    "USE_WANDB = False\n",
    "if USE_WANDB:\n",
    "    wandb.init(\n",
    "        project='video-interpolation',\n",
    "        config=config,\n",
    "        name=f'unet-vimeo90k-{config[\"training\"][\"learning_rate\"]}'\n",
    "    )\n",
    "\n",
    "config['use_wandb'] = USE_WANDB\n",
    "\n",
    "# Criar trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Teste r√°pido: quanto tempo leva para iterar 5 batches?\n",
    "import time\n",
    "print(\"Testing data loading speed...\")\n",
    "start = time.time()\n",
    "for i, batch in enumerate(train_loader):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(f\"Batch {i}: frames shape = {batch['frame1'].shape}\")\n",
    "elapsed = time.time() - start\n",
    "print(f\"5 batches levaram {elapsed:.2f}s ({elapsed/5:.2f}s por batch)\")\n",
    "\n",
    "# Iniciar treinamento\n",
    "trainer.train(num_epochs=config['training']['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cecc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(model, dataset, num_samples=5):\n",
    "    \"\"\"Visualizar resultados do modelo\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Criar diret√≥rio de output se n√£o existir\n",
    "    output_dir = Path('../data/output')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4*num_samples))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            sample = dataset[i]\n",
    "            \n",
    "            frame1 = sample['frame1'].unsqueeze(0).to(device)\n",
    "            frame2_gt = sample['frame2']\n",
    "            frame3 = sample['frame3'].unsqueeze(0).to(device)\n",
    "            \n",
    "            # Predi√ß√£o\n",
    "            frame2_pred = model(frame1, frame3).cpu().squeeze(0)\n",
    "            \n",
    "            # Converter para numpy\n",
    "            f1 = frame1.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "            f2_gt = frame2_gt.permute(1, 2, 0).numpy()\n",
    "            f2_pred = frame2_pred.permute(1, 2, 0).numpy()\n",
    "            f3 = frame3.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "            \n",
    "            # Plot\n",
    "            axes[i, 0].imshow(f1)\n",
    "            axes[i, 0].set_title('Frame 1')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(f2_gt)\n",
    "            axes[i, 1].set_title('Frame 2 (GT)')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(f2_pred)\n",
    "            axes[i, 2].set_title('Frame 2 (Pred)')\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            axes[i, 3].imshow(f3)\n",
    "            axes[i, 3].set_title('Frame 3')\n",
    "            axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    output_path = output_dir / 'interpolation_results.png'\n",
    "    plt.savefig(output_path, dpi=150)\n",
    "    print(f\"‚úì Resultados salvos em: {output_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar resultados\n",
    "visualize_results(model, val_dataset, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_results_advanced(model, dataset, num_samples=3):\n",
    "#     \"\"\"Visualiza√ß√£o avan√ßada com diferen√ßas e m√©tricas\"\"\"\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     from pathlib import Path\n",
    "    \n",
    "#     output_dir = Path('../data/output')\n",
    "#     output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#     model.eval()\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for idx in range(num_samples):\n",
    "#             sample = dataset[idx]\n",
    "            \n",
    "#             frame1 = sample['frame1'].unsqueeze(0).to(device)\n",
    "#             frame2_gt = sample['frame2'].unsqueeze(0).to(device)\n",
    "#             frame3 = sample['frame3'].unsqueeze(0).to(device)\n",
    "            \n",
    "#             # Predi√ß√£o\n",
    "#             frame2_pred = model(frame1, frame3)\n",
    "            \n",
    "#             # Calcular m√©tricas\n",
    "#             psnr = calculate_psnr(frame2_pred, frame2_gt)\n",
    "#             ssim = calculate_ssim(frame2_pred, frame2_gt)\n",
    "            \n",
    "#             # Calcular diferen√ßa absoluta\n",
    "#             diff = torch.abs(frame2_pred - frame2_gt)\n",
    "            \n",
    "#             # Converter para numpy\n",
    "#             f1 = frame1.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "#             f2_gt = frame2_gt.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "#             f2_pred = frame2_pred.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "#             f3 = frame3.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "#             diff_np = diff.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "            \n",
    "#             # Criar figura com 6 subplots\n",
    "#             fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "#             fig.suptitle(f'Sample {idx+1} | PSNR: {psnr:.2f} dB | SSIM: {ssim:.4f}', fontsize=16)\n",
    "            \n",
    "#             # Linha 1: Sequ√™ncia de frames\n",
    "#             axes[0, 0].imshow(f1)\n",
    "#             axes[0, 0].set_title('Frame 1 (Input)', fontsize=12)\n",
    "#             axes[0, 0].axis('off')\n",
    "            \n",
    "#             axes[0, 1].imshow(f2_gt)\n",
    "#             axes[0, 1].set_title('Frame 2 - Ground Truth', fontsize=12)\n",
    "#             axes[0, 1].axis('off')\n",
    "            \n",
    "#             axes[0, 2].imshow(f3)\n",
    "#             axes[0, 2].set_title('Frame 3 (Input)', fontsize=12)\n",
    "#             axes[0, 2].axis('off')\n",
    "            \n",
    "#             # Linha 2: Predi√ß√£o e an√°lise\n",
    "#             axes[1, 0].imshow(f2_pred)\n",
    "#             axes[1, 0].set_title('Frame 2 - Predicted', fontsize=12)\n",
    "#             axes[1, 0].axis('off')\n",
    "            \n",
    "#             axes[1, 1].imshow(diff_np, cmap='hot', vmin=0, vmax=0.5)\n",
    "#             axes[1, 1].set_title('Absolute Difference', fontsize=12)\n",
    "#             axes[1, 1].axis('off')\n",
    "            \n",
    "#             # Compara√ß√£o lado a lado\n",
    "#             comparison = np.concatenate([f2_gt, f2_pred], axis=1)\n",
    "#             axes[1, 2].imshow(comparison)\n",
    "#             axes[1, 2].set_title('GT | Pred (Side by Side)', fontsize=12)\n",
    "#             axes[1, 2].axis('off')\n",
    "            \n",
    "#             plt.tight_layout()\n",
    "            \n",
    "#             # Salvar figura individual\n",
    "#             output_path = output_dir / f'interpolation_analysis_{idx+1}.png'\n",
    "#             plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "#             print(f\"‚úì An√°lise {idx+1} salva em: {output_path}\")\n",
    "#             plt.show()\n",
    "\n",
    "# # Executar visualiza√ß√£o avan√ßada\n",
    "# visualize_results_advanced(model, val_dataset, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8858308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interpolation_gif(model, dataset, sample_idx=0, output_name='interpolation_demo.gif'):\n",
    "    \"\"\"Criar GIF animado mostrando a interpola√ß√£o\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.animation as animation\n",
    "    from pathlib import Path\n",
    "    \n",
    "    output_dir = Path('../data/output')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    model.eval()\n",
    "    sample = dataset[sample_idx]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        frame1 = sample['frame1'].unsqueeze(0).to(device)\n",
    "        frame2_gt = sample['frame2'].unsqueeze(0).to(device)\n",
    "        frame2_pred = model(frame1, sample['frame3'].unsqueeze(0).to(device))\n",
    "        frame3 = sample['frame3'].unsqueeze(0).to(device)\n",
    "    \n",
    "    # Converter para numpy\n",
    "    frames = [\n",
    "        frame1.cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "        frame2_pred.cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "        frame3.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "    ]\n",
    "    \n",
    "    # Criar anima√ß√£o\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    img_display = ax.imshow(frames[0])\n",
    "    title = ax.set_title('Frame 1', fontsize=14)\n",
    "    \n",
    "    def update(frame_idx):\n",
    "        img_display.set_array(frames[frame_idx])\n",
    "        titles = ['Frame 1 (Input)', 'Frame 2 (Interpolated)', 'Frame 3 (Input)']\n",
    "        title.set_text(titles[frame_idx])\n",
    "        return [img_display, title]\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, update, frames=len(frames), \n",
    "                                   interval=500, blit=True, repeat=True)\n",
    "    \n",
    "    output_path = output_dir / output_name\n",
    "    anim.save(output_path, writer='pillow', fps=2)\n",
    "    print(f\"‚úì GIF salvo em: {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# Criar GIF de demonstra√ß√£o\n",
    "try:\n",
    "    create_interpolation_gif(model, val_dataset, sample_idx=0)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao criar GIF: {e}\")\n",
    "    print(\"Certifique-se de ter 'pillow' instalado: poetry add pillow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia-senac-uc14-frame-generation-project-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
